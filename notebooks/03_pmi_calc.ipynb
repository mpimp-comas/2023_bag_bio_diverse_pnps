{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate PMI and Create Plots\n",
    "     \n",
    "PMI values for the reference sets were pre-calculated using the script `calc_pmi` from the `Python_Scripts` folder. The larger datasets (Enamine and ChEMBL NPs) were split in smaller chunks with a custom tool ( `rcsv_split` and its counter part `rcsv_combine`, not part of this repo) and run in parallel for faster calculations.\n",
    "\n",
    "The same reference sets as for the descriptor calculations were used.\n",
    "\n",
    "*DrugBank:*\n",
    "```\n",
    "$ calc_pmi drugbank_5.1.8_appr_inv_full.tsv DRUGBANK_ID -n 100 -t 30\n",
    "Namespace(in_file='drugbank_5.1.8_appr_inv_full.tsv', id_col='DRUGBANK_ID', t=30, v=False, n=100)\n",
    "  In:     4866  Out:     3750  Failed:      0  UndefStereo:    912  Timeout:    204   done.\n",
    "\n",
    "$ mv drugbank_5_pmi.tsv drugbank_5.1.8_appr_inv_full_pmi.tsv\n",
    "```\n",
    "\n",
    "*Enamine 50k Subset:*\n",
    "```\n",
    "$ rcsv_split enamine_adv_full_sample_50k_desc.tsv 10\n",
    "Counting lines...\n",
    "50000 lines in enamine_adv_full_sample_50k_desc.tsv, writing 5001 lines per chunk (10 chunks). The last chunk may have less...\n",
    "\n",
    "$ for jobid in {01..10}; do echo \"Starting job $jobid\"; calc_pmi enamine_adv_full_sample_50k_desc-0$jobid.tsv idnumber -n 100 -t 30 -v >> pmi.txt & sleep 5; done\n",
    "\n",
    "$ grep -F done pmi.txt | sort\n",
    "(enamine_adv_full_sample_50k_desc-001)  In:     5001  Out:     4169  Failed:      0  UndefStereo:    832  Timeout:      0   done.\n",
    "(enamine_adv_full_sample_50k_desc-002)  In:     5001  Out:     4198  Failed:      0  UndefStereo:    803  Timeout:      0   done.\n",
    "(enamine_adv_full_sample_50k_desc-003)  In:     5001  Out:     4177  Failed:      0  UndefStereo:    823  Timeout:      1   done.\n",
    "(enamine_adv_full_sample_50k_desc-004)  In:     5001  Out:     4187  Failed:      0  UndefStereo:    814  Timeout:      0   done.\n",
    "(enamine_adv_full_sample_50k_desc-005)  In:     5001  Out:     4157  Failed:      0  UndefStereo:    843  Timeout:      1   done.\n",
    "(enamine_adv_full_sample_50k_desc-006)  In:     5001  Out:     4220  Failed:      0  UndefStereo:    780  Timeout:      1   done.\n",
    "(enamine_adv_full_sample_50k_desc-007)  In:     5001  Out:     4191  Failed:      0  UndefStereo:    808  Timeout:      2   done.\n",
    "(enamine_adv_full_sample_50k_desc-008)  In:     5001  Out:     4233  Failed:      0  UndefStereo:    766  Timeout:      2   done.\n",
    "(enamine_adv_full_sample_50k_desc-009)  In:     5001  Out:     4178  Failed:      0  UndefStereo:    822  Timeout:      1   done.\n",
    "(enamine_adv_full_sample_50k_desc-010)  In:     4991  Out:     4237  Failed:      0  UndefStereo:    751  Timeout:      3   done.\n",
    "\n",
    "$ rcsv_combine \"enamine_adv_full_sample_50k_desc-0*_pmi.tsv\" enamine_adv_full_sample_50k_pmi.tsv\n",
    "41947 lines from 10 files written to enamine_adv_full_sample_50k_pmi.tsv.\n",
    "```\n",
    "\n",
    "*ChEMBL NPs:*\n",
    "```\n",
    "$ rcsv_split chembl_30_np_full_nocanon_deglyco.tsv 20\n",
    "Counting lines...\n",
    "45679 lines in chembl_30_np_full_nocanon_deglyco.tsv, writing 2284 lines per chunk (20 chunks). The last chunk may have less...\n",
    "\n",
    "$ for jobid in {01..20}; do echo \"Starting job $jobid\"; calc_pmi chembl_30_np_full_nocanon_deglyco-0$jobid.tsv chembl_id -n 100 -t 30 -v >> pmi.txt & sleep 5; done\n",
    "\n",
    "‚ùØ grep -F done pmi.txt | sort\n",
    "(chembl_30_np_full_nocanon_deglyco-001)  In:     2284  Out:     1943  Failed:      0  UndefStereo:    122  Timeout:    219   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-002)  In:     2284  Out:     1645  Failed:      0  UndefStereo:    151  Timeout:    488   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-003)  In:     2284  Out:     1773  Failed:      0  UndefStereo:    167  Timeout:    344   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-004)  In:     2284  Out:     1750  Failed:      0  UndefStereo:    171  Timeout:    363   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-005)  In:     2284  Out:     1783  Failed:      0  UndefStereo:    152  Timeout:    349   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-006)  In:     2284  Out:     1753  Failed:      0  UndefStereo:    244  Timeout:    287   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-007)  In:     2284  Out:     1642  Failed:      0  UndefStereo:    343  Timeout:    299   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-008)  In:     2284  Out:     1764  Failed:      0  UndefStereo:    253  Timeout:    267   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-009)  In:     2284  Out:     1817  Failed:      0  UndefStereo:    243  Timeout:    224   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-010)  In:     2284  Out:     1763  Failed:      0  UndefStereo:    233  Timeout:    288   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-011)  In:     2284  Out:     1788  Failed:      0  UndefStereo:    222  Timeout:    274   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-012)  In:     2284  Out:     1657  Failed:      0  UndefStereo:    320  Timeout:    307   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-013)  In:     2284  Out:     1813  Failed:      0  UndefStereo:    281  Timeout:    190   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-014)  In:     2284  Out:     1695  Failed:      0  UndefStereo:    283  Timeout:    306   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-015)  In:     2284  Out:     1577  Failed:      0  UndefStereo:    247  Timeout:    460   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-016)  In:     2284  Out:     1778  Failed:      0  UndefStereo:    265  Timeout:    241   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-017)  In:     2284  Out:     1721  Failed:      0  UndefStereo:    250  Timeout:    313   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-018)  In:     2284  Out:     1816  Failed:      0  UndefStereo:    208  Timeout:    260   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-019)  In:     2284  Out:     1813  Failed:      0  UndefStereo:    213  Timeout:    258   done.\n",
    "(chembl_30_np_full_nocanon_deglyco-020)  In:     2283  Out:     1707  Failed:      0  UndefStereo:    273  Timeout:    303   done.\n",
    "\n",
    "$ rcsv_combine \"chembl_30_np_full_nocanon_deglyco-0*_pmi.tsv\" chembl_30_np_full_nocanon_deglyco_pmi.tsv\n",
    "34998 lines from 20 files written to chembl_30_np_full_nocanon_deglyco_pmi.tsv.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "def warn(*args, **kwargs):\n",
    "    pass  # to silence scikit-learn warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.warn = warn\n",
    "\n",
    "# Type hints\n",
    "from typing import Iterable, List, Set, Dict, Union, Optional\n",
    "\n",
    "import os, gc\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import scipy.stats as st\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit.Chem import Descriptors as Desc\n",
    "from rdkit.Chem import rdMolDescriptors as rdMolDesc\n",
    "# from rdkit.Chem import Draw\n",
    "# from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Project-local Imports\n",
    "from jupy_tools import plt_style, pmi\n",
    "from jupy_tools import utils as u, mol_view as mv\n",
    "from jupy_tools.utils import info\n",
    "\n",
    "measure_runtime = u.MeasureRuntime()\n",
    "u.timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = 0.02\n",
    "\n",
    "def pmi_plot_contour_overview(df):\n",
    "    plt.figure(figsize=(15, 14));\n",
    "    fig, ax = plt.subplots();\n",
    "    leg_dict = {}\n",
    "    leg_list = [\"Enamine\", \"DrugBank\", \"ChEMBL NP\", config[\"name\"]]\n",
    "    plot_order = [\"DrugBank\", \"ChEMBL NP\", \"Enamine\"]\n",
    "    for ds in plot_order:\n",
    "        # tmp1 = df.query(f\"\"\"DataSet == '{ds}'\"\"\").sample(n=2500).copy().reset_index(drop=True)\n",
    "        tmp1 = df.query(f\"\"\"DataSet == '{ds}'\"\"\").copy().reset_index(drop=True)\n",
    "        x = tmp1[\"PMI1\"]\n",
    "        y = tmp1[\"PMI2\"]\n",
    "\n",
    "        # if ds == \"Enamine\":\n",
    "        #     xmin, xmax = 0, 0.5\n",
    "        #     ymin, ymax = 0.75, 1\n",
    "        # else:\n",
    "        xmin, xmax = 0, 1\n",
    "        ymin, ymax = 0.5, 1\n",
    "\n",
    "        # Peform the kernel density estimate\n",
    "        xx, yy = np.mgrid[xmin:xmax:200j, ymin:ymax:200j]\n",
    "        positions = np.vstack([xx.ravel(), yy.ravel()]).T\n",
    "        values = np.vstack([x, y]).T\n",
    "        kde = KernelDensity(\n",
    "            algorithm=\"kd_tree\",\n",
    "            kernel='gaussian', bandwidth=bandwidth,\n",
    "        ).fit(values)\n",
    "        f = np.reshape(\n",
    "            np.exp(kde.score_samples(positions)), \n",
    "            xx.shape\n",
    "        )\n",
    "\n",
    "        # Contour plot\n",
    "        cntr = ax.contour(xx, yy, f, colors=cmap[ds], levels=10, label=ds, linestyles=\"-\", linewidths=2.0);\n",
    "        leg_elem,_ = cntr.legend_elements()\n",
    "        leg_dict[ds] = leg_elem[7]\n",
    "        # scatter = ax.plot(x, y, 'o', markersize=4, alpha=0.7, color=cmap[ds])\n",
    "\n",
    "    # Overview plot for the internal DataSet\n",
    "    tmp2 = df.query(f\"\"\"DataSet == '{config[\"name\"]}'\"\"\")\n",
    "    x = tmp2[\"PMI1\"]\n",
    "    y = tmp2[\"PMI2\"]\n",
    "    scatter = ax.plot(x, y, 'o', markersize=10, color=cmap[config[\"name\"]])\n",
    "    leg_dict[config[\"name\"]] = scatter[0]\n",
    "\n",
    "    plt.plot([0.0, 0.5, 1.0], [1.0, 0.5, 1.0], color=\"k\", linestyle=\"-\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim(0.5, 1)\n",
    "    plt.xlabel(\"PMI1\");\n",
    "    plt.ylabel(\"PMI2\");\n",
    "    leg_elements = [leg_dict[x] for x in leg_list]\n",
    "    plt.legend(leg_elements, leg_list);\n",
    "    plt.title(\"PMI Plot\");\n",
    "    if USE_SMALLEST_REF_SET:\n",
    "        out_fn = f\"{config['dataset']}/output/pmi_contour_ref_sample\"\n",
    "    else:\n",
    "        out_fn = f\"{config['dataset']}/output/pmi_contour_ref_all\"\n",
    "    plt.savefig(f\"{out_fn}.png\");\n",
    "    plt.savefig(f\"{out_fn}.svg\");\n",
    "\n",
    "def pmi_plot_scatter_overview(df):\n",
    "    plt.figure(figsize=(15, 14));\n",
    "    fig, ax = plt.subplots();\n",
    "    leg_dict = {}\n",
    "    leg_list = [\"Enamine\", \"DrugBank\", \"ChEMBL NP\", config[\"name\"]]\n",
    "    plot_order = [\"ChEMBL NP\", \"DrugBank\", \"Enamine\"]\n",
    "    for ds in plot_order:\n",
    "        tmp1 = df.query(f\"\"\"DataSet == '{ds}'\"\"\").sample(n=3400).copy().reset_index(drop=True)\n",
    "        # tmp1 = df.query(f\"\"\"DataSet == '{ds}'\"\"\").copy().reset_index(drop=True)\n",
    "        x = tmp1[\"PMI1\"]\n",
    "        y = tmp1[\"PMI2\"]\n",
    "        scatter = ax.plot(x, y, 'o', markersize=4, alpha=0.7, color=cmap[ds])\n",
    "        leg_dict[ds] = scatter[0]\n",
    "\n",
    "\n",
    "    # Overview plot for the internal DataSet\n",
    "    tmp2 = df.query(f\"\"\"DataSet == '{config[\"name\"]}'\"\"\")\n",
    "    x = tmp2[\"PMI1\"]\n",
    "    y = tmp2[\"PMI2\"]\n",
    "    scatter = ax.plot(x, y, 'o', markersize=10, color=cmap[config[\"name\"]])\n",
    "    leg_dict[config[\"name\"]] = scatter[0]\n",
    "\n",
    "    plt.plot([0.0, 0.5, 1.0], [1.0, 0.5, 1.0], color=\"k\", linestyle=\"-\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim(0.5, 1)\n",
    "    plt.xlabel(\"PMI1\");\n",
    "    plt.ylabel(\"PMI2\");\n",
    "    leg_elements = [leg_dict[x] for x in leg_list]\n",
    "    plt.legend(leg_elements, leg_list);\n",
    "    plt.title(\"PMI Plot (sampled data)\");\n",
    "    out_fn = f\"{config['dataset']}/output/pmi_scatter_ref_sample\"\n",
    "    plt.savefig(f\"{out_fn}.png\");\n",
    "    plt.savefig(f\"{out_fn}.svg\");\n",
    "\n",
    "def pmi_plot_contour_per_class(df):\n",
    "    plt.figure(figsize=(15, 14));\n",
    "    fig, ax = plt.subplots();\n",
    "    leg_dict = {}\n",
    "    leg_list = []\n",
    "    if config.get(\"show_reference_sets\", True):\n",
    "        leg_list = [\"Enamine\", \"DrugBank\", \"ChEMBL NP\"]\n",
    "        plot_order = [\"DrugBank\", \"ChEMBL NP\", \"Enamine\"]\n",
    "        for ds in plot_order:\n",
    "            # tmp1 = df.query(f\"\"\"DataSet == '{ds}'\"\"\").sample(n=2500).copy().reset_index(drop=True)\n",
    "            tmp1 = df.query(f\"\"\"DataSet == '{ds}'\"\"\").copy().reset_index(drop=True)\n",
    "            x = tmp1[\"PMI1\"]\n",
    "            y = tmp1[\"PMI2\"]\n",
    "\n",
    "            if ds == \"Enamine\":\n",
    "                xmin, xmax = 0, 0.5\n",
    "                ymin, ymax = 0.75, 1\n",
    "            else:\n",
    "                xmin, xmax = 0, 1\n",
    "                ymin, ymax = 0.5, 1\n",
    "\n",
    "            # Peform the kernel density estimate\n",
    "            xx, yy = np.mgrid[xmin:xmax:200j, ymin:ymax:200j]\n",
    "            positions = np.vstack([xx.ravel(), yy.ravel()]).T\n",
    "            values = np.vstack([x, y]).T\n",
    "            kde = KernelDensity(\n",
    "                algorithm=\"kd_tree\",\n",
    "                kernel='gaussian', bandwidth=bandwidth,\n",
    "            ).fit(values)\n",
    "            f = np.reshape(\n",
    "                np.exp(kde.score_samples(positions)), \n",
    "                xx.shape\n",
    "            )\n",
    "\n",
    "            # Contour plot\n",
    "            cntr = ax.contour(xx, yy, f, colors=cmap[ds], levels=10, label=ds, linestyles=\"-\", linewidths=2.0);\n",
    "            leg_elem,_ = cntr.legend_elements()\n",
    "            leg_dict[ds] = leg_elem[7]\n",
    "            # scatter = ax.plot(x, y, 'o', markersize=4, alpha=0.7, color=cmap[ds])\n",
    "\n",
    "    # Per-class plots for the internal DataSet\n",
    "    markers = [\"o\", \"^\", \"s\", \"p\", \"P\", \"*\", \"X\", \"<\", \">\", \"D\", \"v\"]\n",
    "    assert len(markers) == len(set(markers)), \"Markers are not unique.\"\n",
    "    tmp2 = df.query(f\"\"\"DataSet == '{config[\"name\"]}'\"\"\")\n",
    "    cpd_classes = list(sorted(tmp2[\"CpdClass\"].unique()))\n",
    "    assert len(cpd_classes) <= len(markers), \"Not enough markers for the number of classes.\"\n",
    "    class_marker_colors = config.get(\"per_class_colors\", None)\n",
    "    for idx, cc in enumerate(cpd_classes):\n",
    "        tmp_cc = tmp2.query(f\"\"\"CpdClass == '{cc}'\"\"\")\n",
    "        x = tmp_cc[\"PMI1\"]\n",
    "        y = tmp_cc[\"PMI2\"]\n",
    "        if class_marker_colors is None:\n",
    "            scatter = ax.plot(x, y, markers[idx], markersize=10, color=cmap[config[\"name\"]])\n",
    "        else:\n",
    "            scatter = ax.plot(x, y, markers[idx], markersize=10, color=class_marker_colors[idx])\n",
    "        leg_list.append(cc)\n",
    "        leg_dict[cc] = scatter[0]\n",
    "\n",
    "    plt.plot([0.0, 0.5, 1.0], [1.0, 0.5, 1.0], color=\"k\", linestyle=\"-\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim(0.5, 1)\n",
    "    plt.xlabel(\"PMI1\");\n",
    "    plt.ylabel(\"PMI2\");\n",
    "    leg_elements = [leg_dict[x] for x in leg_list]\n",
    "    plt.legend(leg_elements, leg_list);\n",
    "    plt.title(\"PMI Plot (per class)\");\n",
    "    if USE_SMALLEST_REF_SET:\n",
    "        out_fn = f\"{config['dataset']}/output/pmi_per_class_ref_sample\"\n",
    "    else:\n",
    "        out_fn = f\"{config['dataset']}/output/pmi_per_class_ref_all\"\n",
    "    plt.savefig(f\"{out_fn}.png\");\n",
    "    plt.savefig(f\"{out_fn}.svg\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"dataset\": \"pmi\",\n",
    "    \"name\": \"PNPs\",\n",
    "    \"id_col\": \"ENSO_Id\",  # this key is optional\n",
    "    \"extra_columns\": [],\n",
    "    \"has_cpd_ids\": False,\n",
    "    \"per_class_plots\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECALC_PMI = True  # Recalculate the PMI values of the internal data set (SLOW).\n",
    "USE_SMALLEST_REF_SET = False  # Sample all reference sets down to the size of the smallest one.\n",
    "\n",
    "DATA_EN = \"enamine_adv_full\"\n",
    "DATA_DB = \"drugbank_5.1.8_appr_inv_full\"\n",
    "DATA_NP = \"chembl_30_np_full_nocanon_deglyco\"\n",
    "\n",
    "cmap = {\"Enamine\": \"#1f77b4\", \"DrugBank\": \"#ff7f0e\", \"ChEMBL NP\": \"#2ca02c\", config[\"name\"]: \"#d62728\"}\n",
    "\n",
    "os.makedirs(f'{config[\"dataset\"]}/output', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int = u.read_tsv(f\"{config['dataset']}/input/smiles_all.tsv\")\n",
    "\n",
    "if config[\"has_cpd_ids\"]:\n",
    "    # Merge structure Smiles by Compound_Id\n",
    "    config[\"id_col\"] = \"Compound_Id\"\n",
    "    df_comas = u.read_tsv(\"/home/pahl/comas/share/comas_smiles.tsv\")\n",
    "    num_cpds_1 = len(df_int)\n",
    "    df_int = pd.merge(df_int, df_comas, on=\"Compound_Id\", how=\"left\")\n",
    "    num_cpds_2 = len(df_int)\n",
    "    assert num_cpds_1 == num_cpds_2, f\"Only {num_cpds_2} out of {num_cpds_2} compounds were found in the COMAS database.\"\n",
    "if config.get(\"has_salts\", False):\n",
    "    print(\"Standardizing structures...\")\n",
    "    num_cpds_1 = len(df_int)\n",
    "    df_int = u.calc_from_smiles(df_int, \"Smiles_Stand\", u.standardize_mol, filter_nans=False)\n",
    "    df_nan = df_int[df_int[\"Smiles_Stand\"].isna()]\n",
    "    df_int = u.remove_nans(df_int, \"Smiles_Stand\")\n",
    "    num_cpds_2 = len(df_int)\n",
    "    if num_cpds_1 != num_cpds_2:\n",
    "        print(f\"Only {num_cpds_2} out of {num_cpds_1} compounds could be standardized.\")\n",
    "        df_nan\n",
    "        # raise Exception(\"Structure standardization failed.\")\n",
    "    df_int = df_int.drop(\"Smiles\", axis=1)\n",
    "    df_int = df_int.rename(columns={'Smiles_Stand': 'Smiles'})\n",
    "if \"id_col\" not in config:\n",
    "    config[\"id_col\"] = \"Cpd_Id\"\n",
    "    df_int[\"Cpd_Id\"] = df_int.index + 1\n",
    "\n",
    "# The reference data sets already contain the PMI data\n",
    "# Generated by the `calc_pmi.py` script\n",
    "df_en = u.read_tsv(f\"input/{DATA_EN}_sample_50k_pmi.tsv\")\n",
    "df_db = u.read_tsv(f\"input/{DATA_DB}_pmi.tsv\")\n",
    "df_np = u.read_tsv(f\"input/{DATA_NP}_pmi.tsv\")\n",
    "\n",
    "datasets = {\"Enamine\": df_en, \"DrugBank\": df_db, \"ChEMBL NP\": df_np}\n",
    "id_cols = {\"Enamine\": \"idnumber\", \"DrugBank\": \"DRUGBANK_ID\", \"ChEMBL NP\": \"chembl_id\", config[\"name\"]: config[\"id_col\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Structure Overview File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv.write_mol_grid(\n",
    "    df_int, title=config[\"name\"], id_col=config[\"id_col\"], fn=f\"{config['dataset']}/output/mol_grid.html\",\n",
    "    truncate=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding PMI to Internal Data (Slow)\n",
    "\n",
    "Molecules are excluded from the PMI calculation when they have either\n",
    "  - more than one undefined stereocenter, or\n",
    "  - one or more defined stereocenters and at least one undefined stereocenter\n",
    "    (creating diastereomers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RECALC_PMI:\n",
    "    num_cpds_1 = len(df_int)\n",
    "    df_int = df_int.reset_index(drop=True)\n",
    "    df_int = u.calc_from_smiles(df_int, \"Stereo\", pmi.get_stereo_counts)  # Stereo: (num_spec, num_unspec, is_diastereomer)\n",
    "    df_int[[\"NumSpec\", \"NumUnspec\", \"IsDiastereomer\"]] = pd.DataFrame(df_int['Stereo'].tolist(), index=df_int.index)\n",
    "    df_int = df_int.drop(\"Stereo\", axis=1)\n",
    "\n",
    "    df_stereo_fail = df_int[df_int[\"IsDiastereomer\"]].copy()\n",
    "    if len(df_stereo_fail) > 0:\n",
    "        print(f\"{len(df_stereo_fail)} compounds failed the stereo rules. See `molgrid_stereo.html` for details.\")\n",
    "        df_stereo_fail = df_stereo_fail.sort_values([\"NumUnspec\"], ascending=False)\n",
    "        mv.write_mol_grid(\n",
    "            df_stereo_fail, title=f'{config[\"name\"]}_stereo', id_col=config[\"id_col\"], fn=f\"{config['dataset']}/output/mol_grid_stereo.html\",\n",
    "            truncate=20, interactive=True\n",
    "        )\n",
    "    df_int = df_int[~df_int[\"IsDiastereomer\"]].copy()\n",
    "    df_int = df_int.reset_index(drop=True)\n",
    "    num_cpds_2 = len(df_int)\n",
    "    if num_cpds_1 != num_cpds_2:\n",
    "        print(f\"{num_cpds_1-num_cpds_2} compounds were removed because of undefined stereochemistry.\")\n",
    "\n",
    "    u.MIN_NUM_RECS_PROGRESS = 100\n",
    "    df_int = u.calc_from_smiles(df_int, \"PMI\", lambda x: pmi.calc_pmi(x, n_conformers=15, avg=3))\n",
    "    # datasets[config[\"name\"]] = df_int\n",
    "    u.MIN_NUM_RECS_PROGRESS = 500\n",
    "\n",
    "    df_int[['PMI1', 'PMI2']] = pd.DataFrame(df_int['PMI'].tolist(), index=df_int.index)\n",
    "    df_int = df_int.drop(\"PMI\", axis=1)\n",
    "    u.write_tsv(df_int, f\"{config['dataset']}/output/pmi.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate One Data Set for Plotting\n",
    "The internal data is read from disk at the top of this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SMALLEST_REF_SET:\n",
    "    # Use the same size for all reference sets:\n",
    "    len_smallest_ref_set = len(df_db)\n",
    "    print(f\"Sampling all reference sets down to {len_smallest_ref_set} compounds.\")\n",
    "\n",
    "df_int = u.read_tsv(f\"{config['dataset']}/output/pmi.tsv\")\n",
    "datasets[config[\"name\"]] = df_int\n",
    "tmp_list = []\n",
    "for ds in datasets:\n",
    "    if USE_SMALLEST_REF_SET:\n",
    "        if len(datasets[ds]) > len_smallest_ref_set:\n",
    "            tmp = datasets[ds].sample(n=len_smallest_ref_set).copy()\n",
    "        else:\n",
    "            tmp = datasets[ds].copy()\n",
    "    else:\n",
    "        tmp = datasets[ds].copy()\n",
    "    tmp[\"DataSet\"] = ds\n",
    "    tmp = tmp.rename(columns={id_cols[ds]: \"Cpd_Id\"})\n",
    "    tmp_list.append(tmp)\n",
    "\n",
    "cols = [\"Cpd_Id\", \"DataSet\", \"PMI1\", \"PMI2\", \"Duration\"]\n",
    "cols.extend(config[\"extra_columns\"])\n",
    "if config[\"per_class_plots\"]:\n",
    "    cols.append(\"CpdClass\")\n",
    "df_all = pd.concat(tmp_list)[cols]\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "del tmp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "### Plots Calculation Time of Reference Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_all.query(f\"\"\"DataSet != \"{config['name']}\" \"\"\")\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.ecdfplot(data=tmp, x=\"Duration\", stat=\"proportion\", hue=\"DataSet\", palette=cmap)\n",
    "plt.xlabel(\"Duration per structure [s]\")\n",
    "plt.xlim(0, 30);\n",
    "# plt.legend();\n",
    "plt.title(f\"Distribution of PMI Calculation Duration\")\n",
    "plt.savefig(f\"{config['dataset']}/output/ecdf_duration.png\");\n",
    "plt.savefig(f\"{config['dataset']}/output/ecdf_duration.svg\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMI Overview Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.get(\"overview_plots\", True):\n",
    "    pmi_plot_contour_overview(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMI Scatter Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.get(\"overview_plots\", True):\n",
    "    pmi_plot_scatter_overview(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMI Per Class Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"per_class_plots\"]:\n",
    "    pmi_plot_contour_per_class(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_runtime.elapsed()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "bag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39b18661f0ab0911dfb8298bcee5220064328a49f2c82e71a54d89c8a20caef3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
